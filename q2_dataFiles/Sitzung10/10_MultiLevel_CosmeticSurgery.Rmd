---
title: "Multilevel Models 1: Hierarchische Datenstrukturen"
author: "R-Klaus"
date: "1 Juli 2019"
output: html_document
---

# Szenario: Kosmetische Chirurgie und Lebensqualität

In einer medizinisch-psychologischen Studie wurde untersucht, ob Menschen, die sich einer nicht medizinisch notwendigen Operation unterzogen haben, zu einem bestimmten Zeitpunkt nach der OP eine höhere Lebensqualität/-zufriedenheit aufweisen als Personen auf der Warteliste (Kontrollgruppe).Dabei soll dafür kontrolliert werden, in welcher von 10 Kliniken die Personen ihre OP hatten bzw. auf der Warteliste standen. 

Siehe Andy Field, Kapitel 19.

```{r echo=FALSE, out.width = '50%'}
knitr::include_graphics("cartoon2.jpg")
```

Folgende Hypothese wurden aufgestellt:

**Ein Modell, das die Durchführung einer Operation und die durchführende Klinik beinhaltet, sagt die spätere Lebensqualität (PostQoL) von Personen vorher.**

# Datenstruktur erkennen und Multilevel-Modell aufstellen

Es liegt eine hierarchische Datenstruktur vor. Die Patient*innen und ihre PostQoL sind zehn Kliniken untergeordnet. Die Personen innerhalb einer Klinik werden sich in ihren Outcomes möglicherweise ähnlicher sein als sie es zu den Personen in anderen Kliniken sind. Unser Modell sollte diese Struktur berücksichtigen. 

Ob eine Operation durchgeführt wurde oder nicht, wird als ganz normaler Prädiktor (fixed effect) ins Modell aufgenommen - genau so wie bisher bekannt. Der Einfluss der Klinik kann mit einem random intercept und/oder einem random slope eingefangen werden. Wir werden prüfen, welche dieser Komponenten nötig sind, um die Daten bestmöglich zu beschreiben. 

**Random intercept** = der y-Achsenabschnitt der 10 Kliniken unterscheidet sich. Intercept = Wert des Kriteriums, wenn alle Prädiktoren gleich Null sind. Ein signifikantes random intercept würde hier also bedeuten, dass die PostQoL der Patient*innen sich auch zwischen den Kliniken unterscheidet, wenn gar keine Operation durchgeführt wurde. (Das könnte beispielsweise daran liegen, dass die Warteliste-Gruppe in manchen Kliniken besser betreut oder beraten wird als in anderen. Oder es liegt gar kein kausaler Zusammenhang vor, sondern manche Kliniken liegen geographisch einfach in wohlhabenderen Gegenden, in denen die Lebensqualität generell höher ist. Immerhin wurden die Personen den Kliniken ja vermutlich nicht randomisiert zugeteilt.)

**Random slope** = der Einfluss des fixed factors Operation unterscheidet sich zwischen den Kliniken: In manchen Kliniken unterscheiden sich die behandelte Gruppe und die Kontrollgruppe in ihrer späteren Lebensqualität vielleicht stärker als in anderen, in manchen vielleicht auch gar nicht. Oder: In manchen Kliniken geht die Veränderung in eine positive Richtung, in anderen sogar in eine negative. Das random slope könnte also die Qualität der verschiedenen Kliniken einfangen (wobei die möglicherweise resultierenden Unterschiede natürlich auch durch andere Faktoren erklärbar sein könnten, beispielsweise könnten manche Kliniken eher von Menschen besucht werden, die ohnehin gesünder sind oder ähnliches). 

Ein Modell kann beide oder nur einen dieser random factors beinhalten. Bedeutung random intercept ohne random slope = Ohne Intervention ist die PostQoL zwischen den Kliniken unterschiedlich. Das Durchführen der OP führt dann aber in jeder Klinik in gleichem Maße zu einer Veränderung der PostQoL. Bedeutung random slope ohne random intercept = Ohne Intervention gibt es keine Unterschiede zwischen den Kliniken. Wenn eine OP durchgeführt wird, sind die Auswirkungen der OP auf die PostQoL aber je nach Klinik unterschiedlich. Welche random factors man ins Modell aufnimmt, hängt von den inhaltlichen Hypothesen ab. In unserem Fall sind beide Effekte plausibel und wir sollten daher prüfen, welche Komponenten unser Modell beinhalten sollte, um die Daten bestmöglich zu beschreiben. 

**Vorgehen:**

Wir werden mittels mehrerer, schrittweiser Modellvergleiche prüfen, ob ein Modell mit random intercept und random slope unsere Daten vorhersagen kann: 

```{r echo=FALSE}
knitr::include_graphics(c("modell.png"))
```

* Personenindex i = Patient*in

* Gruppenindex j = Klinik

* beta0,j: mittleres Intercept über Kliniken hinweg

* u0,j: Standardabweichung der Intercepts für die verschiedenen Kliniken um das mittlere Intercept

* beta1,j: mittlere Steigung für den Faktor Operation über die Kliniken hinweg

* u1,j: Standardabweichung der Steigungen für die verschiedenen Kliniken


# Statistische Hypothesen über Modell

Siehe Formelsammlung:

```{r echo=FALSE}
knitr::include_graphics(c("SH.png"))
```

## Schritte beim Vorgehen:

VL, Folie 26 (siehe darauffolgende Folien für noch mehr Details):

```{r echo=FALSE}
knitr::include_graphics(c("Schritte.png"))
```

# Einlesen der Daten, Laden der nötigen Pakete

```{r message=FALSE, warning=FALSE}
data <- read.csv("surgery_data.csv",sep=";")
```

neue Pakete ggf. installieren:
```{r, message=FALSE}
library(Rcmdr)

#install.packages("nlme",dependencies=T)
library(nlme) #für Berechnen des Modells
#install.packages("lmtest",dependencies=T)
library(lmtest) #für likelihood ratio tests
#install.packages("rcompanion",dependencies=T)
library(rcompanion) #für Effektgrößen
```

# Graphiken erstellen

**Graphik ohne Krankenhäuser**:

Erstmal könnte man sich ansehen, wie der Zusammenhang aussieht, wenn man die 10 Krankenhäuser nicht mit einbezieht. 

RCmdr: Grafiken, Streudiagramm:

```{r}
data$Surgery_label <- factor(data$Surgery_label)

with(data, plotMeans(Post_QoL, Surgery_label, error.bars="conf.int", 
  level=0.95, connect=TRUE))
```

Weiterhin könnten wir uns anschauen, wie die Mittelwerte aussehen, wenn man Clinic mit einbezieht:

```{r}
data$Clinic_label <- factor(data$Clinic_label)


with(data, plotMeans(Post_QoL, Clinic_label, Surgery_label, 
  error.bars="conf.int", level=0.95, connect=TRUE, legend.pos="farright"))
```

Um eine Grafik zu erhalten, die ähnlich zu der Visualisierung in der VL ist (und optisch näher am linearen Modell), können wir auch ein Streudiagramm mit den folgenden Spezifikationen erstellen:

* x-Achse: surgery
* y-Achse PostQoL
* Gruppierungsfaktor Clinic
* Kleinst-Quadratlinie bei Optionen auswählen

```{r}
scatterplot(Post_QoL~Surgery_num | Clinic_label, regLine=TRUE, smooth=FALSE,
   boxplots=FALSE, by.groups=TRUE, data=data)
```

Hier sieht man, dass die Steigungen (zwischen Kontroll- und OP-Gruppe) für unterschiedliche Kliniken durchaus unterschiedlich aussehen. Weiterhin sieht man, dass auch in der Kontrollgruppe bereits Unterschiede zwischen Kliniken zu bestehen scheinen.

# Schrittweiser Modellvergleich

**Strategie:**

1. Nullmodell aufstellen: Vergleich mit einem Modell mit random intercept. Zeigt, ob es baseline-Unterschiede zwischen Kliniken gibt und ein random intercept demnach angemessen ist. 

2. Wenn Modell mit RI besser als Nullmodell: Aufstellen eines Modells mit random intercept **plus** fixed effect für den Prädiktor Operation, Vergleich mit dem Modell mit nur random intercept. Zeigt uns, ob der Faktor Operation über die Kliniken hinweg einen Einfluss hat.

3. Wenn Modell mit RI und fixed factor OP besser als Modell mit nur RI: Aufstellen eines Modells mit random intercept, Prädiktor **plus** random slope für Prädiktor. Vergleich mit dem vorherigen Modell. Zeigt uns, ob der Einfluss der Operation in den verschiedenen Kliniken unterschiedlich ist. 

**Schritt1: Nullmodell vs. Random Intercept**:

```{r}
Null <- gls(Post_QoL ~ 1, data = data, method="ML")

summary(Null)
```

Generalized least squares = auf kleinsten Quadraten basierende Methode, Regressionsparameter auch dann effizient zu schätzen, wenn Abhängigkeiten in den Daten vorliegen (zb. hierarchische Struktur).

Maximum likelihood: Schätzmethode für die Parameter. Es werden diejenigen Parameter gesucht, unter denen die erhaltenen Daten am wahrscheinlichsten sind. 

Random intercept-Modell (Achtung: jetzt mit lme-Funktion):

(Es ist für die Berechnung hier übrigens egal, ob man die numerische Clinic-Variable oder den Clinic-Faktor (mit labels) einsetzt.)

```{r}
RI <- lme(Post_QoL ~ 1, data= data, random = ~1|Clinic_num, method="ML")
summary(RI)
```

Unter "random effects" erhalten wir jetzt die Standardabweichung des Intercepts für die verschiedenen Kliniken. (Und die der Residuen.)

Wie tippt man den vertikalen Strich ein (der ist links neben "Y")?

```{r echo=FALSE}
knitr::include_graphics(c("strich.png"))
```

Das AIC des zweiten Modells ist kleiner als das des ersten, was eine bessere Passung auf die Daten anzeigt. Wir prüfen nun, ob diese Verbesserung signifikant ist:

```{r}
lrtest(Null,RI)
```

Die Verbesserung ist signifikant: wir sollten den random intercept beibehalten.

Die Richtung des Unterschieds (welches Modell jetzt besser ist) geht aus dem lrtest-Output selbst nicht hervor. Das müssen wir am AIC der Modelle ablesen (niedriger = besser).

**Schritt 2: RI-Modell gegen RI-Modell plus fixed factor (unser Prädiktor):**

```{r}
RI_pred <- lme(Post_QoL ~ Surgery_num, data = data, random = ~1|Clinic_num, method="ML")

summary(RI_pred)
```

Das AIC ist im Vergleich zum vorheigen Modell leicht gesunken, der Koeffizient für den fixed factor Surgery zudem (knapp) nicht signifikant. 

Test der beiden Modelle gegeneinander:

```{r}
lrtest(RI,RI_pred)
```

Sie unterscheiden sich nicht signifikant. Über die verschiedenen Kliniken hinweg scheint sich die Durchführung einer Operation also nicht auf die spätere Lebensqualität auszuwirken. 

Es könnte aber sein, dass sich die Effekte zwischen den Kliniken so unterscheiden, dass sie sich, wenn man über alle Kliniken mittelt, ausgleichen. Ein solches Muster können wir nur über ein random slope einfangen. 

**Schritt 3: Modell mit RI und fixed factor Operation gegen Modell mit RI, fixed factor Operation und random slope für Operation:**

```{r}
RI_pred_RS <- lme(Post_QoL ~ Surgery_num, data = data, random = ~Surgery_num|Clinic_num, method="ML")

summary(RI_pred_RS)
```

Unter "random effects" finden sich nun die geschätzten Standardabweichungen für Intercept und Steigung.

Das AIC ist deutlich gesunken.

Wir prüfen, ob das Modell mit random slope signifikant besser ist als das vorherige:

```{r}
lrtest(RI_pred,RI_pred_RS)
```

Das Modell mit random intercept und random slope beschreibt unsere Daten also am besten. 

Die statistische Hypothese kann angenommen werden.

# Effektgröße


Hier kann eine Annäherung an R-Squared berechnet werden, bei der das final gewählte Modell mit dem Modell, das nur das random intercept enthält, verglichen wird (siehe Formelsammlung):

```{r}
nagelkerke(RI_pred_RS,RI)
```

Cox & Snell oder Nagelkerke können als R^2-Annäherung interpretiert werden. 

# Exkurs: Was passiert, wenn man mit den Daten einfach eine Anova oder eine Regression rechnet?

## Anova

Zweifaktoriell über Commander

```{r}
AnovaModel.1 <- lm(Post_QoL ~ Clinic_label*Surgery_label, data=data,
   contrasts=list(Clinic_label ="contr.Sum", Surgery_label 
  ="contr.Sum"))
Anova(AnovaModel.1)
```

Wir würden hier also zu einem ähnlichen Schluss kommen. Was dahintersteckt, ist aber aufwändiger als ein Multilevelmodell, da im Hintergrund ja Dummy-Variablen für den Faktor Klinik angelegt werden. Hier wären das 9 Dummy-Variablen, aber wenn es noch mehr Gruppen gäbe, könnten es auch deutlich mehr werden. Bei einem Multilevelmodell würde bei diesem Beispiel immer dieselbe Anzahl von Parametern geschätzt (die Mittelwerte und Streuungen für Intercept und Slope, wenn man sie als random effects einsetzt), auch wenn wir 500 Kliniken vergleichen würden. 

## Regression

Achtung: hier muss zumindest für Clinic der Faktor als Prädiktor gewählt werden, sonst macht der Output keinen Sinn (die Zahlen 1-10 würden als kontinuierliche Variable verstanden. Bei surgery, wo es nur 0 und 1 gibt, macht das keinen Unterschied, der gleiche Gruppenunterschied würde in beiden Fällen ausgegeben. Der Konsistenz halber wird hier allerdings ebenfalls der Faktor verwendet.)

```{r}
summary(lm(Post_QoL ~ Surgery_label*Clinic_label, data = data))
```

Die dummykodierten Kliniken und vor allem die vielen Interaktionsvariablen sind nicht besonders leicht zu interpretieren. Daher funktioniert das Vorgehen zwar, aber ist an dieser Stelle nicht besonders informativ (und davon abgesehen gilt dasselbe Argument bzgl. der potentiell vielen Dummy-Variablen wie oben.)

## PS.:

Nicolaas Jan Dirk Nagelkerke wünscht alles Gute für die Klausur!

```{r echo=FALSE, out.width = '50%'}
knitr::include_graphics("nagelkerke.png")
```

